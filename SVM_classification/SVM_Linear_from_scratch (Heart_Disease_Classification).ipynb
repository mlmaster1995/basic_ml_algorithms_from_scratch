{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Support Vector Machine (linear) from scratch\n",
    "## 1.1 dataset link: https://www.kaggle.com/ronitf/heart-disease-uci/download\n",
    "## 1.2 Sklearn test is involved for comparing with same parameter setup\n",
    "## 1.3 Linear SVM can score 25%-30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statistics as st\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data process functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load & split data into train & test set\n",
    "def load_data(name):\n",
    "    path = os.getcwd()\n",
    "    data_path = os.path.join(path, name)\n",
    "    data_raw = pd.read_csv(data_path)\n",
    "    data_index = data_raw.keys()\n",
    "\n",
    "    #print(data_index)\n",
    "    return (data_raw, data_index)\n",
    "\n",
    "\n",
    "## plot histogram of each attribute\n",
    "def plot_hist(data_refine, data_refine_index):\n",
    "    data_zip = list(zip(*data_refine))\n",
    "\n",
    "    for index in range(len(data_zip)):\n",
    "        each_attr = data_zip[index]\n",
    "        low_b = math.floor(min(each_attr))\n",
    "        upp_b = math.ceil(max(each_attr))\n",
    "        plt.hist(each_attr, range=[low_b, upp_b])\n",
    "        plt.title(data_refine_index[index], loc='center')\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "## split data_test from data_train, split_ration=0.7, 70% data for training, 30% of data for testing\n",
    "def split_train_test_data(data_refine, data_refine_target, split_ratio, rand=True):\n",
    "    data_train = []\n",
    "    data_train_target = []\n",
    "    data_test=[]\n",
    "    data_test_target=[]\n",
    "    train_length = int(len(data_refine) * split_ratio)\n",
    "\n",
    "    if rand:\n",
    "        for index in range(train_length):\n",
    "            pos = random.randint(0, len(data_refine) - 1)\n",
    "            data_train.append(data_refine.pop(pos))\n",
    "            data_train_target.append(data_refine_target.pop(pos))\n",
    "\n",
    "        data_test = data_refine\n",
    "        data_test_target = data_refine_target\n",
    "\n",
    "    else:\n",
    "\n",
    "        data_refine_dic={}\n",
    "\n",
    "        for index in range(len(data_refine_target)):\n",
    "            if data_refine_target[index] not in data_refine_dic:\n",
    "                data_refine_dic[data_refine_target[index]]=[]\n",
    "                data_refine_dic[data_refine_target[index]].append(data_refine[index])\n",
    "            else:\n",
    "                data_refine_dic[data_refine_target[index]].append(data_refine[index])\n",
    "\n",
    "        for key in list(data_refine_dic.keys()):\n",
    "\n",
    "            train_length = int(len(data_refine_dic[key]) * split_ratio)\n",
    "\n",
    "            for index in range(train_length-1):\n",
    "                data_train.append(data_refine_dic[key].pop(0))\n",
    "                data_train_target.append(data_refine_target.pop(0))\n",
    "\n",
    "\n",
    "            for item in data_refine_dic[key]:\n",
    "                data_test.append(item)\n",
    "            data_test_target = data_refine_target\n",
    "\n",
    "    return (data_train, data_train_target, data_test, data_test_target)\n",
    "\n",
    "\n",
    "# shuffle the categarized data\n",
    "def shuffle_data_ca(data_ca, data_ca_target):\n",
    "    data_shf = []\n",
    "    data_shf_target = []\n",
    "    for i in range(len(data_ca)):\n",
    "        loc = random.randint(0, len(data_ca) - 1)\n",
    "        data_shf.append(data_ca.pop(loc))\n",
    "        data_shf_target.append(data_ca_target.pop(loc))\n",
    "\n",
    "    return (data_shf, data_shf_target)\n",
    "\n",
    "# scale all data into [0,1]\n",
    "def scale_data(dt_train):\n",
    "    col_max_min = [(np.min(col), np.max(col)) for col in list(zip(*dt_train)) ]\n",
    "    for row_index in range(len(dt_train)):\n",
    "        for col_index in range(len(dt_train[row_index])):\n",
    "            col_min = col_max_min[col_index][0]\n",
    "            col_max = col_max_min[col_index][1]\n",
    "            dt_train[row_index][col_index] = (dt_train[row_index][col_index]-col_min)/(col_max-col_min)\n",
    "    return dt_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 3. SVM functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate random weight w0,w1,w2,w3.....\n",
    "def generate_weight(num_attr, start, end):\n",
    "    wt_array=[]\n",
    "    for i in range(num_attr):\n",
    "        wt_array.append(random.uniform(start, end))\n",
    "    return wt_array\n",
    "\n",
    "## SVM linear func\n",
    "def SVM( dt_train, dt_train_target, wt_arr, kernal='linear', C=1, stp=1, epoch_limit=1000, stp_limit=1e-300, show_bias=True, stp_show=False):\n",
    "\n",
    "    if kernal == 'linear':\n",
    "        epoch = 0\n",
    "        hinge_loss_all = 0\n",
    "        reg_val = 1 / C\n",
    "        while epoch <= epoch_limit:\n",
    "            hinge_loss = []\n",
    "            hinge_loss_last = hinge_loss_all\n",
    "\n",
    "\n",
    "            for index in range(len(dt_train)):\n",
    "\n",
    "                r = np.dot(dt_train[index], wt_arr) * dt_train_target[index]\n",
    "\n",
    "                if r >= 1:\n",
    "                    hinge_loss.append(0)\n",
    "                    wt_arr = wt_arr - stp * reg_val * wt_arr\n",
    "                else:\n",
    "                    hinge_loss.append(1 - r)\n",
    "                    wt_arr = wt_arr + stp * (dt_train_target[index] * np.array(dt_train[index]) - reg_val * wt_arr)\n",
    "\n",
    "                hinge_loss_all = sum(hinge_loss)\n",
    "\n",
    "            if stp_show:\n",
    "                print('epoch:', epoch, ',hinge_loss:', round(hinge_loss_all, 5), ',step: ', stp)\n",
    "\n",
    "            if abs(hinge_loss_last - hinge_loss_all) <= 0.1:\n",
    "                stp = stp * 0.01\n",
    "\n",
    "            if stp <= stp_limit:\n",
    "                break\n",
    "\n",
    "            epoch += 1\n",
    "\n",
    "        if show_bias:\n",
    "            error = 0\n",
    "            if stp_show:\n",
    "                print('vector length: ')\n",
    "            for index in range(len(dt_train)):\n",
    "                r = np.dot(dt_train[index], wt_arr) * dt_train_target[index]\n",
    "                if r < 0:\n",
    "                    error += 1\n",
    "                if stp_show:\n",
    "                    print(r)\n",
    "            bias = error / len(dt_train) * 100\n",
    "            print('data train length: ', len(dt_train))\n",
    "            print('bias: ', bias, '%\\n')\n",
    "\n",
    "        return (wt_arr, bias/100, C)\n",
    "\n",
    "## SVM test func\n",
    "def SVM_test(dt_test, dt_test_target, wt_arr, C):\n",
    "    error = 0\n",
    "    reg_val = 1 / C\n",
    "    for index in range(len(dt_test)):\n",
    "\n",
    "        r = np.dot(dt_test[index], wt_arr) * dt_test_target[index]\n",
    "        if r < 0:\n",
    "            error += 1\n",
    "    # print('test data length: ', len(dt_test))\n",
    "    # print('variance: ', error / len(dt_test) * 100, '%\\n')\n",
    "\n",
    "    score = 1- error / len(dt_test)\n",
    "\n",
    "    return (score, len(dt_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Test- Load & Modify Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>age</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.098447</td>\n",
       "      <td>-0.068653</td>\n",
       "      <td>0.279351</td>\n",
       "      <td>0.213678</td>\n",
       "      <td>0.121308</td>\n",
       "      <td>-0.116211</td>\n",
       "      <td>-0.398522</td>\n",
       "      <td>0.096801</td>\n",
       "      <td>0.210013</td>\n",
       "      <td>-0.168814</td>\n",
       "      <td>0.276326</td>\n",
       "      <td>0.068001</td>\n",
       "      <td>-0.225439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sex</td>\n",
       "      <td>-0.098447</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.049353</td>\n",
       "      <td>-0.056769</td>\n",
       "      <td>-0.197912</td>\n",
       "      <td>0.045032</td>\n",
       "      <td>-0.058196</td>\n",
       "      <td>-0.044020</td>\n",
       "      <td>0.141664</td>\n",
       "      <td>0.096093</td>\n",
       "      <td>-0.030711</td>\n",
       "      <td>0.118261</td>\n",
       "      <td>0.210041</td>\n",
       "      <td>-0.280937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cp</td>\n",
       "      <td>-0.068653</td>\n",
       "      <td>-0.049353</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.047608</td>\n",
       "      <td>-0.076904</td>\n",
       "      <td>0.094444</td>\n",
       "      <td>0.044421</td>\n",
       "      <td>0.295762</td>\n",
       "      <td>-0.394280</td>\n",
       "      <td>-0.149230</td>\n",
       "      <td>0.119717</td>\n",
       "      <td>-0.181053</td>\n",
       "      <td>-0.161736</td>\n",
       "      <td>0.433798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>trestbps</td>\n",
       "      <td>0.279351</td>\n",
       "      <td>-0.056769</td>\n",
       "      <td>0.047608</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.123174</td>\n",
       "      <td>0.177531</td>\n",
       "      <td>-0.114103</td>\n",
       "      <td>-0.046698</td>\n",
       "      <td>0.067616</td>\n",
       "      <td>0.193216</td>\n",
       "      <td>-0.121475</td>\n",
       "      <td>0.101389</td>\n",
       "      <td>0.062210</td>\n",
       "      <td>-0.144931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>chol</td>\n",
       "      <td>0.213678</td>\n",
       "      <td>-0.197912</td>\n",
       "      <td>-0.076904</td>\n",
       "      <td>0.123174</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013294</td>\n",
       "      <td>-0.151040</td>\n",
       "      <td>-0.009940</td>\n",
       "      <td>0.067023</td>\n",
       "      <td>0.053952</td>\n",
       "      <td>-0.004038</td>\n",
       "      <td>0.070511</td>\n",
       "      <td>0.098803</td>\n",
       "      <td>-0.085239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>fbs</td>\n",
       "      <td>0.121308</td>\n",
       "      <td>0.045032</td>\n",
       "      <td>0.094444</td>\n",
       "      <td>0.177531</td>\n",
       "      <td>0.013294</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.084189</td>\n",
       "      <td>-0.008567</td>\n",
       "      <td>0.025665</td>\n",
       "      <td>0.005747</td>\n",
       "      <td>-0.059894</td>\n",
       "      <td>0.137979</td>\n",
       "      <td>-0.032019</td>\n",
       "      <td>-0.028046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>restecg</td>\n",
       "      <td>-0.116211</td>\n",
       "      <td>-0.058196</td>\n",
       "      <td>0.044421</td>\n",
       "      <td>-0.114103</td>\n",
       "      <td>-0.151040</td>\n",
       "      <td>-0.084189</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.044123</td>\n",
       "      <td>-0.070733</td>\n",
       "      <td>-0.058770</td>\n",
       "      <td>0.093045</td>\n",
       "      <td>-0.072042</td>\n",
       "      <td>-0.011981</td>\n",
       "      <td>0.137230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>thalach</td>\n",
       "      <td>-0.398522</td>\n",
       "      <td>-0.044020</td>\n",
       "      <td>0.295762</td>\n",
       "      <td>-0.046698</td>\n",
       "      <td>-0.009940</td>\n",
       "      <td>-0.008567</td>\n",
       "      <td>0.044123</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.378812</td>\n",
       "      <td>-0.344187</td>\n",
       "      <td>0.386784</td>\n",
       "      <td>-0.213177</td>\n",
       "      <td>-0.096439</td>\n",
       "      <td>0.421741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>exang</td>\n",
       "      <td>0.096801</td>\n",
       "      <td>0.141664</td>\n",
       "      <td>-0.394280</td>\n",
       "      <td>0.067616</td>\n",
       "      <td>0.067023</td>\n",
       "      <td>0.025665</td>\n",
       "      <td>-0.070733</td>\n",
       "      <td>-0.378812</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.288223</td>\n",
       "      <td>-0.257748</td>\n",
       "      <td>0.115739</td>\n",
       "      <td>0.206754</td>\n",
       "      <td>-0.436757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>oldpeak</td>\n",
       "      <td>0.210013</td>\n",
       "      <td>0.096093</td>\n",
       "      <td>-0.149230</td>\n",
       "      <td>0.193216</td>\n",
       "      <td>0.053952</td>\n",
       "      <td>0.005747</td>\n",
       "      <td>-0.058770</td>\n",
       "      <td>-0.344187</td>\n",
       "      <td>0.288223</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.577537</td>\n",
       "      <td>0.222682</td>\n",
       "      <td>0.210244</td>\n",
       "      <td>-0.430696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>slope</td>\n",
       "      <td>-0.168814</td>\n",
       "      <td>-0.030711</td>\n",
       "      <td>0.119717</td>\n",
       "      <td>-0.121475</td>\n",
       "      <td>-0.004038</td>\n",
       "      <td>-0.059894</td>\n",
       "      <td>0.093045</td>\n",
       "      <td>0.386784</td>\n",
       "      <td>-0.257748</td>\n",
       "      <td>-0.577537</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.080155</td>\n",
       "      <td>-0.104764</td>\n",
       "      <td>0.345877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ca</td>\n",
       "      <td>0.276326</td>\n",
       "      <td>0.118261</td>\n",
       "      <td>-0.181053</td>\n",
       "      <td>0.101389</td>\n",
       "      <td>0.070511</td>\n",
       "      <td>0.137979</td>\n",
       "      <td>-0.072042</td>\n",
       "      <td>-0.213177</td>\n",
       "      <td>0.115739</td>\n",
       "      <td>0.222682</td>\n",
       "      <td>-0.080155</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.151832</td>\n",
       "      <td>-0.391724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>thal</td>\n",
       "      <td>0.068001</td>\n",
       "      <td>0.210041</td>\n",
       "      <td>-0.161736</td>\n",
       "      <td>0.062210</td>\n",
       "      <td>0.098803</td>\n",
       "      <td>-0.032019</td>\n",
       "      <td>-0.011981</td>\n",
       "      <td>-0.096439</td>\n",
       "      <td>0.206754</td>\n",
       "      <td>0.210244</td>\n",
       "      <td>-0.104764</td>\n",
       "      <td>0.151832</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.344029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>target</td>\n",
       "      <td>-0.225439</td>\n",
       "      <td>-0.280937</td>\n",
       "      <td>0.433798</td>\n",
       "      <td>-0.144931</td>\n",
       "      <td>-0.085239</td>\n",
       "      <td>-0.028046</td>\n",
       "      <td>0.137230</td>\n",
       "      <td>0.421741</td>\n",
       "      <td>-0.436757</td>\n",
       "      <td>-0.430696</td>\n",
       "      <td>0.345877</td>\n",
       "      <td>-0.391724</td>\n",
       "      <td>-0.344029</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age       sex        cp  trestbps      chol       fbs  \\\n",
       "age       1.000000 -0.098447 -0.068653  0.279351  0.213678  0.121308   \n",
       "sex      -0.098447  1.000000 -0.049353 -0.056769 -0.197912  0.045032   \n",
       "cp       -0.068653 -0.049353  1.000000  0.047608 -0.076904  0.094444   \n",
       "trestbps  0.279351 -0.056769  0.047608  1.000000  0.123174  0.177531   \n",
       "chol      0.213678 -0.197912 -0.076904  0.123174  1.000000  0.013294   \n",
       "fbs       0.121308  0.045032  0.094444  0.177531  0.013294  1.000000   \n",
       "restecg  -0.116211 -0.058196  0.044421 -0.114103 -0.151040 -0.084189   \n",
       "thalach  -0.398522 -0.044020  0.295762 -0.046698 -0.009940 -0.008567   \n",
       "exang     0.096801  0.141664 -0.394280  0.067616  0.067023  0.025665   \n",
       "oldpeak   0.210013  0.096093 -0.149230  0.193216  0.053952  0.005747   \n",
       "slope    -0.168814 -0.030711  0.119717 -0.121475 -0.004038 -0.059894   \n",
       "ca        0.276326  0.118261 -0.181053  0.101389  0.070511  0.137979   \n",
       "thal      0.068001  0.210041 -0.161736  0.062210  0.098803 -0.032019   \n",
       "target   -0.225439 -0.280937  0.433798 -0.144931 -0.085239 -0.028046   \n",
       "\n",
       "           restecg   thalach     exang   oldpeak     slope        ca  \\\n",
       "age      -0.116211 -0.398522  0.096801  0.210013 -0.168814  0.276326   \n",
       "sex      -0.058196 -0.044020  0.141664  0.096093 -0.030711  0.118261   \n",
       "cp        0.044421  0.295762 -0.394280 -0.149230  0.119717 -0.181053   \n",
       "trestbps -0.114103 -0.046698  0.067616  0.193216 -0.121475  0.101389   \n",
       "chol     -0.151040 -0.009940  0.067023  0.053952 -0.004038  0.070511   \n",
       "fbs      -0.084189 -0.008567  0.025665  0.005747 -0.059894  0.137979   \n",
       "restecg   1.000000  0.044123 -0.070733 -0.058770  0.093045 -0.072042   \n",
       "thalach   0.044123  1.000000 -0.378812 -0.344187  0.386784 -0.213177   \n",
       "exang    -0.070733 -0.378812  1.000000  0.288223 -0.257748  0.115739   \n",
       "oldpeak  -0.058770 -0.344187  0.288223  1.000000 -0.577537  0.222682   \n",
       "slope     0.093045  0.386784 -0.257748 -0.577537  1.000000 -0.080155   \n",
       "ca       -0.072042 -0.213177  0.115739  0.222682 -0.080155  1.000000   \n",
       "thal     -0.011981 -0.096439  0.206754  0.210244 -0.104764  0.151832   \n",
       "target    0.137230  0.421741 -0.436757 -0.430696  0.345877 -0.391724   \n",
       "\n",
       "              thal    target  \n",
       "age       0.068001 -0.225439  \n",
       "sex       0.210041 -0.280937  \n",
       "cp       -0.161736  0.433798  \n",
       "trestbps  0.062210 -0.144931  \n",
       "chol      0.098803 -0.085239  \n",
       "fbs      -0.032019 -0.028046  \n",
       "restecg  -0.011981  0.137230  \n",
       "thalach  -0.096439  0.421741  \n",
       "exang     0.206754 -0.436757  \n",
       "oldpeak   0.210244 -0.430696  \n",
       "slope    -0.104764  0.345877  \n",
       "ca        0.151832 -0.391724  \n",
       "thal      1.000000 -0.344029  \n",
       "target   -0.344029  1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load raw data and show correlation with target column\n",
    "data_raw, data_raw_index=load_data('heart_disease_data.csv')\n",
    "data_raw.corr(method='pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  restecg  thalach  exang  oldpeak  slope  ca  thal  \\\n",
       "0   63    1   3       145        0      150      0      2.3      0   0     1   \n",
       "1   37    1   2       130        1      187      0      3.5      0   0     2   \n",
       "2   41    0   1       130        0      172      0      1.4      2   0     2   \n",
       "3   56    1   1       120        1      178      0      0.8      2   0     2   \n",
       "4   57    0   0       120        1      163      1      0.6      2   0     2   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop 'chol', 'fbs' du to low correlation to the target \n",
    "data_raw = data_raw.drop(columns=['chol', 'fbs'])\n",
    "data_raw_index = data_raw.keys()\n",
    "data_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# covert from dataset dataframe to list\n",
    "data_lst = data_raw.values.tolist()\n",
    "\n",
    "# refine the dataset by removing the target columns \n",
    "data_rf = [dt[:-1] for dt in data_lst]\n",
    "data_rf_target = list(list(zip(*data_lst))[-1])\n",
    "\n",
    "# normalize the every columns value to [0,1]\n",
    "data_rf = scale_data(data_rf)\n",
    "\n",
    "# add one more column with value '1' into dataset for bias\n",
    "for dt in data_rf:\n",
    "    dt.append(1)\n",
    "\n",
    "# modify dataset target to '1' or '-1'\n",
    "for index in range(len(data_rf_target)):\n",
    "    if data_rf_target[index] == 0.0:\n",
    "        data_rf_target[index] = -1\n",
    "\n",
    "# convert data_raw_index to a list so as to match the dataset columns\n",
    "data_index = data_raw_index.values.tolist()\n",
    "data_index = data_index[:-1]\n",
    "\n",
    "# split the data_rf into train & test sets\n",
    "# split ratio is 0.8\n",
    "dt_train, dt_train_target, dt_test, dt_test_target = \\\n",
    "    split_train_test_data(data_rf, data_rf_target, split_ratio=0.8, rand=False)\n",
    "\n",
    "# shuffle all training data\n",
    "dt_train, dt_train_target = shuffle_data_ca(dt_train, dt_train_target);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 2, 3]]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[[1,2,3]]\n",
    "a[-1].insert(0,1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1957912401506121"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " abs(121.53696368015022 -121.34117243999961)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Linear SVM from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate random initial weight in [0,1]\n",
    "#wt_lst = generate_weight(len(data_index)+1, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error with initial randome weight:  31.25 %\n",
      "\n",
      "final weight: [ 0.09582597 -0.99526074  1.39254867 -1.78049152 -0.1505056   3.84062239\n",
      " -0.66776045 -1.08132111 -0.66188109 -2.89313275 -1.90334204  2.21859269] \n",
      "\n",
      "train data length:  240\n",
      "bias:  20.0 %\n",
      "\n",
      "test data length:  63\n",
      "variance:  69.84126984126983 %\n",
      "\n",
      "score: 30.15873015873016 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### weight is genrated by[95]\n",
    "wt_lst=[\n",
    "0.20717319464152695,\n",
    "0.6206984801546556,\n",
    "0.43006365979581385,\n",
    "0.4580060620231049,\n",
    "0.33883164044002245,\n",
    "0.36739188157541647,\n",
    "0.5832498372259184,\n",
    "0.9209212798422121,\n",
    "0.6737554996556483,\n",
    "0.5508969453938781,\n",
    "0.21220708634760788,\n",
    "0.43266411739534283,]\n",
    "wt_arr = np.array(wt_lst)\n",
    "\n",
    "### calculate the error rate with initial weight\n",
    "error=0;\n",
    "for index in range(len(dt_train)):\n",
    "    r = np.dot(dt_train[index], wt_arr) * dt_train_target[index]\n",
    "    if r<0:\n",
    "        error+=1\n",
    "print('error with initial randome weight: ', error/len(dt_train)*100, '%\\n')\n",
    "\n",
    "\n",
    "# SVM linear algorithm\n",
    "C=1000\n",
    "stp=2\n",
    "epoch_limit =1000\n",
    "epoch=0\n",
    "hinge_loss_all=0\n",
    "while epoch <= epoch_limit:\n",
    "    hinge_loss=[]\n",
    "    hinge_loss_last = hinge_loss_all\n",
    "    reg_val = 1 / C\n",
    "\n",
    "    for index in range(len(dt_train)):\n",
    "\n",
    "        r = np.dot(dt_train[index], wt_arr)*dt_train_target[index]\n",
    "\n",
    "        if r>=1:\n",
    "            hinge_loss.append(0)\n",
    "            wt_arr = wt_arr - stp*reg_val*wt_arr\n",
    "        else:\n",
    "            hinge_loss.append(1-r)\n",
    "            wt_arr = wt_arr + stp*(dt_train_target[index]*np.array(dt_train[index])-reg_val*wt_arr)\n",
    "\n",
    "        hinge_loss_all = sum(hinge_loss)\n",
    "\n",
    "    if abs(hinge_loss_last - hinge_loss_all)<=0.1:\n",
    "        stp = stp * 0.01\n",
    "\n",
    "    if stp<=1e-300:\n",
    "        break\n",
    "\n",
    "    epoch+=1\n",
    "\n",
    "### print the final weight \n",
    "print('final weight:', wt_arr,'\\n')\n",
    "\n",
    "### calculate the bias\n",
    "error=0;\n",
    "for index in range(len(dt_train)):\n",
    "    reg_val = 1 / C\n",
    "    r = np.dot(dt_train[index], wt_arr) * dt_train_target[index]\n",
    "    if r<0:\n",
    "        error+=1\n",
    "print('train data length: ', len(dt_train))\n",
    "print('bias: ', error/len(dt_train)*100, '%\\n')\n",
    "\n",
    "\n",
    "### calculate the cross-validation & final accuracy\n",
    "error=0;\n",
    "for index in range(len(dt_test)):\n",
    "    reg_val = 1 / C\n",
    "    r = np.dot(dt_test[index], wt_arr) * dt_test_target[index]\n",
    "    if r<0:\n",
    "        error+=1\n",
    "print('test data length: ',len(dt_test))\n",
    "print('variance: ', error/len(dt_test)*100, '%\\n')\n",
    "print('score:', (1-error/len(dt_test))*100, '%\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Sklearn Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "data_raw, data_raw_index=load_data('heart_disease_data.csv')\n",
    "data_raw = data_raw.drop(columns=['chol', 'fbs'])\n",
    "data_raw_index = data_raw.keys()\n",
    "\n",
    "# covert from dataset dataframe to list\n",
    "data_lst = data_raw.values.tolist()\n",
    "\n",
    "# refine the dataset by removing the target columns \n",
    "data_rf = [dt[:-1] for dt in data_lst]\n",
    "data_rf_target = list(list(zip(*data_lst))[-1])\n",
    "\n",
    "# normalize the every columns value to [0,1]\n",
    "data_rf = scale_data(data_rf)\n",
    "\n",
    "# add one more column with value '1' into dataset for bias\n",
    "# for dt in data_rf:\n",
    "#     dt.append(1)\n",
    "\n",
    "# modify dataset target to '1' or '-1'\n",
    "# for index in range(len(data_rf_target)):\n",
    "#     if data_rf_target[index] == 0.0:\n",
    "#         data_rf_target[index] = -1\n",
    "\n",
    "# convert data_raw_index to a list so as to match the dataset columns\n",
    "# data_index = data_raw_index.values.tolist()\n",
    "# data_index = data_index[:-1]\n",
    "\n",
    "# split the data_rf into train & test sets\n",
    "# split ratio is 0.8\n",
    "dt_train, dt_train_target, dt_test, dt_test_target = \\\n",
    "    split_train_test_data(data_rf, data_rf_target, split_ratio=0.8, rand=False)\n",
    "\n",
    "# shuffle all training data\n",
    "dt_train, dt_train_target = shuffle_data_ca(dt_train, dt_train_target);\n",
    "\n",
    "\n",
    "\n",
    "model = SVC(C=100,gamma='scale', kernel='linear')\n",
    "model.fit(dt_train, dt_train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 25.396825396825395 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = model.score(dt_test, dt_test_target)\n",
    "print('score:',score*100, '%\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
